trainingset size: 100000
validationset size: 10000
input_dims:  (64, 64, 3)
nb_labels:  200
nb_labels: 200
x_train.shape  (100000, 64, 64, 3)
y_train.shape  (100000, 200)
x_test.shape  (10000, 64, 64, 3)
y_test.shape  (10000, 200)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 58, 62, 92)        5888      
_________________________________________________________________
activation_1 (Activation)    (None, 58, 62, 92)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 28, 30, 92)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 30, 256)       118016    
_________________________________________________________________
activation_2 (Activation)    (None, 24, 30, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 14, 256)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 14, 384)        295296    
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 14, 384)        442752    
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 14, 384)        442752    
_________________________________________________________________
activation_3 (Activation)    (None, 5, 14, 384)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 6, 384)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4608)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              9439232   
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dense_3 (Dense)              (None, 200)               409800    
=================================================================
Total params: 15,350,088
Trainable params: 15,350,088
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
 - 75s - loss: 5.2999 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 2/50
 - 67s - loss: 5.2991 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 3/50
 - 67s - loss: 5.2991 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 4/50
 - 67s - loss: 5.2991 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 5/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 6/50
 - 67s - loss: 5.2991 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 7/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 8/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 9/50
 - 67s - loss: 5.2991 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 10/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 11/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 12/50
 - 67s - loss: 5.2991 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 13/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 14/50
 - 67s - loss: 5.2991 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 15/50
 - 67s - loss: 5.2991 - acc: 0.0049 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 16/50
 - 67s - loss: 5.2991 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 17/50
 - 67s - loss: 5.2991 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 18/50
 - 67s - loss: 5.2991 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 19/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 20/50
 - 67s - loss: 5.2991 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 21/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 22/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 23/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 24/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 25/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 26/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 27/50
 - 67s - loss: 5.2991 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 28/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 29/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 30/50
 - 67s - loss: 5.2991 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 31/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 32/50
 - 67s - loss: 5.2991 - acc: 0.0039 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 33/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 34/50
 - 67s - loss: 5.2991 - acc: 0.0040 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 35/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 36/50
 - 67s - loss: 5.2991 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 37/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 38/50
 - 67s - loss: 5.2991 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 39/50
 - 67s - loss: 5.2991 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 40/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2984 - val_acc: 0.0050
Epoch 41/50
 - 67s - loss: 5.2991 - acc: 0.0048 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 42/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 43/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 44/50
 - 67s - loss: 5.2991 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 45/50
 - 67s - loss: 5.2991 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 46/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 47/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 48/50
 - 67s - loss: 5.2991 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 49/50
 - 67s - loss: 5.2991 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050
Epoch 50/50
 - 67s - loss: 5.2991 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050
training history:
{'val_loss': [5.298346427917481, 5.298346710205078, 5.298345448303222, 5.298344702911377, 5.2983483215332035, 5.298347608947754, 5.298342866516113, 5.298342453765869, 5.298343743133545, 5.298348544311524, 5.298345288848877, 5.298346373748779, 5.298347222137451, 5.298344592285156, 5.298347855377197, 5.2983407791137695, 5.298349870300293, 5.298348744964599, 5.298345523834229, 5.298344873046875, 5.298344000244141, 5.298344484710693, 5.298341606140137, 5.298343894958496, 5.298346290588379, 5.298347748565674, 5.2983459259033205, 5.298346043395996, 5.2983455596923825, 5.298341939544677, 5.2983424209594725, 5.298344136810303, 5.298344602203369, 5.29834298324585, 5.298342407226563, 5.298344856262207, 5.298343984985352, 5.298344711303711, 5.298345997619629, 5.298350596618652, 5.298345829010009, 5.298338869476319, 5.298339366912842, 5.2983471870422365, 5.298343684387207, 5.298348839569091, 5.298347013854981, 5.298344268798828, 5.298343266296387, 5.29834444732666], 'val_acc': [0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005], 'loss': [5.299915291137696, 5.299071571044922, 5.299069046630859, 5.299084705352783, 5.299077026062012, 5.299088171691895, 5.299087694244385, 5.299077569122314, 5.299085294189453, 5.299077266845703, 5.299090274353027, 5.299072984313965, 5.299079151153564, 5.299082993469239, 5.299057776489258, 5.299096239318848, 5.299076466064453, 5.299100473175049, 5.299079305419922, 5.299093921508789, 5.2990925914001465, 5.299085901184082, 5.299096657409668, 5.299084930877686, 5.299100430755615, 5.299068454437256, 5.299091420593261, 5.299074145355225, 5.299101598968506, 5.2991079733276365, 5.299094271240234, 5.299084559326172, 5.29907808883667, 5.299086903686524, 5.29907570602417, 5.299084251861572, 5.299092934112549, 5.299085035400391, 5.299081484832763, 5.299088942108154, 5.299078194580078, 5.299092810516357, 5.299098965148926, 5.299074967651367, 5.299091042480469, 5.299072407379151, 5.299079517211914, 5.299084095458984, 5.2990976007080075, 5.2990906854248045], 'acc': [0.00407, 0.00457, 0.00453, 0.00456, 0.0044, 0.00412, 0.00434, 0.00438, 0.00418, 0.00428, 0.00429, 0.00424, 0.00426, 0.0045, 0.00486, 0.00422, 0.00457, 0.00422, 0.00433, 0.00412, 0.00436, 0.00431, 0.00436, 0.00438, 0.00431, 0.00442, 0.00419, 0.00444, 0.00432, 0.00413, 0.00426, 0.00394, 0.00435, 0.00403, 0.00428, 0.00451, 0.00428, 0.00418, 0.00445, 0.00445, 0.00485, 0.00433, 0.00443, 0.00448, 0.00459, 0.00436, 0.00443, 0.00455, 0.00431, 0.00441]}
Training time: 
3376.2745213508606
Evaluation results:  [5.298344451904297, 0.005]
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 58, 62, 92)        5888      
_________________________________________________________________
activation_4 (Activation)    (None, 58, 62, 92)        0         
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 28, 30, 92)        0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 24, 30, 256)       118016    
_________________________________________________________________
activation_5 (Activation)    (None, 24, 30, 256)       0         
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 11, 14, 256)       0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 9, 14, 384)        295296    
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 7, 14, 384)        442752    
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 5, 14, 384)        442752    
_________________________________________________________________
activation_6 (Activation)    (None, 5, 14, 384)        0         
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 2, 6, 384)         0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 4608)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 2048)              9439232   
_________________________________________________________________
dense_5 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dense_6 (Dense)              (None, 200)               409800    
=================================================================
Total params: 15,350,088
Trainable params: 15,350,088
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
 - 58s - loss: 5.0233 - acc: 0.0289 - val_loss: 4.7027 - val_acc: 0.0618
Epoch 2/50
 - 58s - loss: 4.5136 - acc: 0.0849 - val_loss: 4.2690 - val_acc: 0.1149
Epoch 3/50
 - 58s - loss: 4.1326 - acc: 0.1354 - val_loss: 4.0990 - val_acc: 0.1349
Epoch 4/50
 - 58s - loss: 3.8333 - acc: 0.1778 - val_loss: 3.9220 - val_acc: 0.1696
Epoch 5/50
 - 58s - loss: 3.5750 - acc: 0.2180 - val_loss: 3.6876 - val_acc: 0.2052
Epoch 6/50
 - 58s - loss: 3.3400 - acc: 0.2566 - val_loss: 3.5691 - val_acc: 0.2195
Epoch 7/50
 - 58s - loss: 3.1051 - acc: 0.2957 - val_loss: 3.5627 - val_acc: 0.2287
Epoch 8/50
 - 58s - loss: 2.8584 - acc: 0.3390 - val_loss: 3.5105 - val_acc: 0.2462
Epoch 9/50
 - 58s - loss: 2.5930 - acc: 0.3860 - val_loss: 3.5689 - val_acc: 0.2452
Epoch 10/50
 - 58s - loss: 2.2936 - acc: 0.4431 - val_loss: 3.7300 - val_acc: 0.2307
Epoch 11/50
 - 58s - loss: 1.9681 - acc: 0.5073 - val_loss: 3.9618 - val_acc: 0.2334
Epoch 12/50
 - 58s - loss: 1.6071 - acc: 0.5845 - val_loss: 4.2330 - val_acc: 0.2290
Epoch 13/50
 - 58s - loss: 1.2512 - acc: 0.6621 - val_loss: 4.6178 - val_acc: 0.2168
Epoch 14/50
 - 58s - loss: 0.9186 - acc: 0.7436 - val_loss: 5.3562 - val_acc: 0.2137
Epoch 15/50
 - 58s - loss: 0.6749 - acc: 0.8053 - val_loss: 5.6525 - val_acc: 0.2088
Epoch 16/50
 - 58s - loss: 0.4877 - acc: 0.8562 - val_loss: 5.9984 - val_acc: 0.2152
Epoch 17/50
 - 58s - loss: 0.3835 - acc: 0.8852 - val_loss: 6.5479 - val_acc: 0.2157
Epoch 18/50
 - 58s - loss: 0.3240 - acc: 0.9027 - val_loss: 6.8500 - val_acc: 0.2135
Epoch 19/50
 - 58s - loss: 0.2583 - acc: 0.9220 - val_loss: 6.8336 - val_acc: 0.2141
Epoch 20/50
 - 58s - loss: 0.2005 - acc: 0.9401 - val_loss: 7.0817 - val_acc: 0.2198
Epoch 21/50
 - 58s - loss: 0.1631 - acc: 0.9514 - val_loss: 7.3500 - val_acc: 0.2159
Epoch 22/50
 - 58s - loss: 0.1301 - acc: 0.9612 - val_loss: 7.4828 - val_acc: 0.2162
Epoch 23/50
 - 58s - loss: 0.1128 - acc: 0.9665 - val_loss: 7.5799 - val_acc: 0.2190
Epoch 24/50
 - 58s - loss: 0.1231 - acc: 0.9637 - val_loss: 7.6049 - val_acc: 0.2206
Epoch 25/50
 - 58s - loss: 0.1017 - acc: 0.9700 - val_loss: 7.7493 - val_acc: 0.2205
Epoch 26/50
 - 58s - loss: 0.0924 - acc: 0.9729 - val_loss: 7.7509 - val_acc: 0.2146
Epoch 27/50
 - 58s - loss: 0.0709 - acc: 0.9788 - val_loss: 8.0075 - val_acc: 0.2205
Epoch 28/50
 - 58s - loss: 0.0667 - acc: 0.9803 - val_loss: 7.9018 - val_acc: 0.2194
Epoch 29/50
 - 58s - loss: 0.0727 - acc: 0.9790 - val_loss: 8.2514 - val_acc: 0.2210
Epoch 30/50
 - 58s - loss: 0.0788 - acc: 0.9771 - val_loss: 8.0906 - val_acc: 0.2228
Epoch 31/50
 - 58s - loss: 0.0623 - acc: 0.9814 - val_loss: 8.1318 - val_acc: 0.2218
Epoch 32/50
 - 58s - loss: 0.0524 - acc: 0.9848 - val_loss: 8.1677 - val_acc: 0.2166
Epoch 33/50
 - 57s - loss: 0.0395 - acc: 0.9886 - val_loss: 8.2735 - val_acc: 0.2236
Epoch 34/50
 - 57s - loss: 0.0411 - acc: 0.9880 - val_loss: 8.6545 - val_acc: 0.2147
Epoch 35/50
 - 58s - loss: 0.0600 - acc: 0.9825 - val_loss: 8.3181 - val_acc: 0.2182
Epoch 36/50
 - 57s - loss: 0.0510 - acc: 0.9848 - val_loss: 8.4461 - val_acc: 0.2197
Epoch 37/50
 - 57s - loss: 0.0353 - acc: 0.9901 - val_loss: 8.5045 - val_acc: 0.2316
Epoch 38/50
 - 58s - loss: 0.0280 - acc: 0.9921 - val_loss: 8.4557 - val_acc: 0.2291
Epoch 39/50
 - 57s - loss: 0.0223 - acc: 0.9943 - val_loss: 8.6778 - val_acc: 0.2238
Epoch 40/50
 - 57s - loss: 0.0241 - acc: 0.9930 - val_loss: 8.5591 - val_acc: 0.2249
Epoch 41/50
 - 57s - loss: 0.0270 - acc: 0.9929 - val_loss: 8.7088 - val_acc: 0.2231
Epoch 42/50
 - 57s - loss: 0.0365 - acc: 0.9893 - val_loss: 8.6913 - val_acc: 0.2179
Epoch 43/50
 - 57s - loss: 0.0452 - acc: 0.9864 - val_loss: 8.7321 - val_acc: 0.2152
Epoch 44/50
 - 57s - loss: 0.0389 - acc: 0.9889 - val_loss: 8.4560 - val_acc: 0.2253
Epoch 45/50
 - 57s - loss: 0.0273 - acc: 0.9927 - val_loss: 8.7729 - val_acc: 0.2202
Epoch 46/50
 - 57s - loss: 0.0339 - acc: 0.9907 - val_loss: 8.7174 - val_acc: 0.2206
Epoch 47/50
 - 57s - loss: 0.0338 - acc: 0.9905 - val_loss: 8.6214 - val_acc: 0.2273
Epoch 48/50
 - 57s - loss: 0.0302 - acc: 0.9917 - val_loss: 8.6755 - val_acc: 0.2257
Epoch 49/50
 - 57s - loss: 0.0262 - acc: 0.9926 - val_loss: 8.7738 - val_acc: 0.2166
Epoch 50/50
 - 57s - loss: 0.0224 - acc: 0.9936 - val_loss: 8.8385 - val_acc: 0.2225
training history:
{'val_loss': [4.702681052398682, 4.269045203399658, 4.099046278381348, 3.9220074878692626, 3.6875552673339844, 3.56907905960083, 3.5627364479064942, 3.510500601196289, 3.568862075805664, 3.7299881683349607, 3.9617980651855467, 4.233035028839112, 4.617848037719726, 5.356180316925049, 5.652468469238281, 5.998360045623779, 6.547856863403321, 6.850027349853516, 6.833591035461426, 7.081659275054932, 7.3499796699523925, 7.482838451385498, 7.579886224365234, 7.604908227539062, 7.749276644897461, 7.750912548828125, 8.007457326507568, 7.901766793060303, 8.25141830291748, 8.090618392944336, 8.131813201904297, 8.167656290435792, 8.273507011413574, 8.654490678405761, 8.318061813354491, 8.446096546173095, 8.50450334777832, 8.455657627868652, 8.677802789306641, 8.559061833190919, 8.708826733398437, 8.691267999267579, 8.732082731628418, 8.456042115783692, 8.772934516906739, 8.717388529968261, 8.621354888916015, 8.675499240112305, 8.773798492431641, 8.83846428527832], 'val_acc': [0.0618, 0.1149, 0.1349, 0.1696, 0.2052, 0.2195, 0.2287, 0.2462, 0.2452, 0.2307, 0.2334, 0.229, 0.2168, 0.2137, 0.2088, 0.2152, 0.2157, 0.2135, 0.2141, 0.2198, 0.2159, 0.2162, 0.219, 0.2206, 0.2205, 0.2146, 0.2205, 0.2194, 0.221, 0.2228, 0.2218, 0.2166, 0.2236, 0.2147, 0.2182, 0.2197, 0.2316, 0.2291, 0.2238, 0.2249, 0.2231, 0.2179, 0.2152, 0.2253, 0.2202, 0.2206, 0.2273, 0.2257, 0.2166, 0.2225], 'loss': [5.02338291595459, 4.5135946530151365, 4.132541904449463, 3.8333511668395994, 3.5750834648132326, 3.3400530670166018, 3.105187283782959, 2.8585006483459474, 2.593211238746643, 2.293587922439575, 1.968195262260437, 1.6071986155319213, 1.251348631286621, 0.9184974262237549, 0.6748247816467285, 0.48763097183704374, 0.3835817217540741, 0.3239542240977287, 0.2582397177886963, 0.2004400753247738, 0.16311385808646678, 0.13006803589344024, 0.11277884159088135, 0.12310955134421588, 0.10175636522680521, 0.09236565245479346, 0.07095635414823889, 0.06673124178059399, 0.07275607393167913, 0.07882672034300864, 0.06226577983297408, 0.05241265841729939, 0.03952200515206903, 0.04115647295413539, 0.059939959905445574, 0.050922926067598163, 0.035286209573503584, 0.028046440416099504, 0.02228863725666888, 0.024117786909490825, 0.027007553159417583, 0.036524419721774753, 0.04516782330617308, 0.038914342191517355, 0.02726059343718458, 0.033864829264013095, 0.033848387027774006, 0.03018925892581232, 0.026220367110599763, 0.022423866880619897], 'acc': [0.02892, 0.08488, 0.13538, 0.17775, 0.21799, 0.25659, 0.29571, 0.33893, 0.38597, 0.44309, 0.50732, 0.5845, 0.66211, 0.74367, 0.80527, 0.85625, 0.88516, 0.90277, 0.92201, 0.94014, 0.95137, 0.9612, 0.96644, 0.96371, 0.97, 0.97293, 0.97879, 0.9803, 0.97895, 0.97713, 0.9814, 0.98481, 0.98862, 0.98798, 0.98253, 0.98485, 0.99011, 0.99211, 0.99432, 0.993, 0.99292, 0.98931, 0.98637, 0.98885, 0.99266, 0.99065, 0.99046, 0.99172, 0.99256, 0.9936]}
Training time: 
2880.639000415802
Evaluation results:  [8.838464295196534, 0.2225]
