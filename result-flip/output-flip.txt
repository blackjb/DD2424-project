trainingset size: 100000
validationset size: 10000
input_dims:  (64, 64, 3)
nb_labels:  200
nb_labels: 200
x_train.shape  (100000, 64, 64, 3)
y_train.shape  (100000, 200)
x_test.shape  (10000, 64, 64, 3)
y_test.shape  (10000, 200)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 58, 61, 48)        4080      
_________________________________________________________________
activation_1 (Activation)    (None, 58, 61, 48)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 28, 30, 48)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 30, 128)       30848     
_________________________________________________________________
activation_2 (Activation)    (None, 24, 30, 128)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 14, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 14, 192)        73920     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 14, 192)        110784    
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 14, 128)        73856     
_________________________________________________________________
activation_3 (Activation)    (None, 5, 14, 128)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 6, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1536)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              3147776   
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dense_3 (Dense)              (None, 200)               409800    
=================================================================
Total params: 8,047,416
Trainable params: 8,047,416
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
 - 36s - loss: 5.0478 - acc: 0.0273 - val_loss: 4.8599 - val_acc: 0.0477
Epoch 2/50
 - 27s - loss: 4.5827 - acc: 0.0753 - val_loss: 4.4288 - val_acc: 0.0892
Epoch 3/50
 - 27s - loss: 4.2277 - acc: 0.1221 - val_loss: 4.1086 - val_acc: 0.1385
Epoch 4/50
 - 27s - loss: 3.9600 - acc: 0.1604 - val_loss: 3.8785 - val_acc: 0.1691
Epoch 5/50
 - 27s - loss: 3.7371 - acc: 0.1942 - val_loss: 3.7210 - val_acc: 0.1955
Epoch 6/50
 - 27s - loss: 3.5527 - acc: 0.2225 - val_loss: 3.6068 - val_acc: 0.2118
Epoch 7/50
 - 27s - loss: 3.3909 - acc: 0.2488 - val_loss: 3.5740 - val_acc: 0.2220
Epoch 8/50
 - 27s - loss: 3.2407 - acc: 0.2758 - val_loss: 3.4634 - val_acc: 0.2388
Epoch 9/50
 - 27s - loss: 3.1025 - acc: 0.2981 - val_loss: 3.4296 - val_acc: 0.2492
Epoch 10/50
 - 27s - loss: 2.9614 - acc: 0.3230 - val_loss: 3.4353 - val_acc: 0.2507
Epoch 11/50
 - 27s - loss: 2.8245 - acc: 0.3461 - val_loss: 3.4546 - val_acc: 0.2459
Epoch 12/50
 - 27s - loss: 2.6904 - acc: 0.3696 - val_loss: 3.3817 - val_acc: 0.2561
Epoch 13/50
 - 27s - loss: 2.5424 - acc: 0.3990 - val_loss: 3.4550 - val_acc: 0.2537
Epoch 14/50
 - 27s - loss: 2.3968 - acc: 0.4259 - val_loss: 3.5156 - val_acc: 0.2517
Epoch 15/50
 - 27s - loss: 2.2490 - acc: 0.4536 - val_loss: 3.5639 - val_acc: 0.2611
Epoch 16/50
 - 27s - loss: 2.0839 - acc: 0.4876 - val_loss: 3.7110 - val_acc: 0.2516
Epoch 17/50
 - 27s - loss: 1.9288 - acc: 0.5165 - val_loss: 3.8496 - val_acc: 0.2487
Epoch 18/50
 - 27s - loss: 1.7709 - acc: 0.5518 - val_loss: 3.8954 - val_acc: 0.2516
Epoch 19/50
 - 27s - loss: 1.6119 - acc: 0.5846 - val_loss: 4.0523 - val_acc: 0.2482
Epoch 20/50
 - 27s - loss: 1.4406 - acc: 0.6222 - val_loss: 4.4312 - val_acc: 0.2398
Epoch 21/50
 - 27s - loss: 1.2907 - acc: 0.6564 - val_loss: 4.5999 - val_acc: 0.2350
Epoch 22/50
 - 27s - loss: 1.1559 - acc: 0.6871 - val_loss: 4.6522 - val_acc: 0.2244
Epoch 23/50
 - 27s - loss: 1.0144 - acc: 0.7206 - val_loss: 4.8623 - val_acc: 0.2374
Epoch 24/50
 - 27s - loss: 0.8950 - acc: 0.7526 - val_loss: 5.0357 - val_acc: 0.2424
Epoch 25/50
 - 27s - loss: 0.7886 - acc: 0.7772 - val_loss: 5.3432 - val_acc: 0.2327
Epoch 26/50
 - 27s - loss: 0.6962 - acc: 0.8004 - val_loss: 5.6481 - val_acc: 0.2417
Epoch 27/50
 - 27s - loss: 0.6245 - acc: 0.8192 - val_loss: 5.6538 - val_acc: 0.2369
Epoch 28/50
 - 27s - loss: 0.5400 - acc: 0.8421 - val_loss: 5.9294 - val_acc: 0.2321
Epoch 29/50
 - 27s - loss: 0.4963 - acc: 0.8541 - val_loss: 6.1221 - val_acc: 0.2384
Epoch 30/50
 - 27s - loss: 0.4423 - acc: 0.8672 - val_loss: 6.4332 - val_acc: 0.2335
Epoch 31/50
 - 27s - loss: 0.4036 - acc: 0.8796 - val_loss: 6.3508 - val_acc: 0.2331
Epoch 32/50
 - 27s - loss: 0.3593 - acc: 0.8925 - val_loss: 6.7318 - val_acc: 0.2381
Epoch 33/50
 - 27s - loss: 0.3310 - acc: 0.9010 - val_loss: 6.6225 - val_acc: 0.2364
Epoch 34/50
 - 27s - loss: 0.3043 - acc: 0.9082 - val_loss: 6.8157 - val_acc: 0.2285
Epoch 35/50
 - 27s - loss: 0.2845 - acc: 0.9146 - val_loss: 6.9149 - val_acc: 0.2296
Epoch 36/50
 - 27s - loss: 0.2603 - acc: 0.9212 - val_loss: 7.0890 - val_acc: 0.2333
Epoch 37/50
 - 27s - loss: 0.2483 - acc: 0.9238 - val_loss: 6.9625 - val_acc: 0.2392
Epoch 38/50
 - 27s - loss: 0.2240 - acc: 0.9311 - val_loss: 7.0855 - val_acc: 0.2369
Epoch 39/50
 - 27s - loss: 0.2108 - acc: 0.9365 - val_loss: 7.2339 - val_acc: 0.2310
Epoch 40/50
 - 27s - loss: 0.2102 - acc: 0.9357 - val_loss: 7.3260 - val_acc: 0.2339
Epoch 41/50
 - 27s - loss: 0.1819 - acc: 0.9451 - val_loss: 7.3495 - val_acc: 0.2351
Epoch 42/50
 - 27s - loss: 0.1636 - acc: 0.9502 - val_loss: 7.5254 - val_acc: 0.2358
Epoch 43/50
 - 27s - loss: 0.1671 - acc: 0.9486 - val_loss: 7.4085 - val_acc: 0.2396
Epoch 44/50
 - 27s - loss: 0.1569 - acc: 0.9520 - val_loss: 7.5311 - val_acc: 0.2355
Epoch 45/50
 - 27s - loss: 0.1415 - acc: 0.9567 - val_loss: 7.6796 - val_acc: 0.2342
Epoch 46/50
 - 27s - loss: 0.1433 - acc: 0.9560 - val_loss: 7.6250 - val_acc: 0.2377
Epoch 47/50
 - 27s - loss: 0.1355 - acc: 0.9583 - val_loss: 7.7010 - val_acc: 0.2353
Epoch 48/50
 - 27s - loss: 0.1340 - acc: 0.9599 - val_loss: 7.8450 - val_acc: 0.2409
Epoch 49/50
 - 27s - loss: 0.1180 - acc: 0.9644 - val_loss: 7.7743 - val_acc: 0.2346
Epoch 50/50
 - 27s - loss: 0.1264 - acc: 0.9610 - val_loss: 7.7672 - val_acc: 0.2344
training history:
{'val_loss': [4.859883865356445, 4.428827395629883, 4.108631278991699, 3.8785477844238283, 3.7210222885131836, 3.606822477722168, 3.5739506843566895, 3.4634188148498537, 3.429582139968872, 3.435319199371338, 3.4546117809295653, 3.3817009620666503, 3.4549750701904296, 3.5156093563079835, 3.5638783393859863, 3.711009588241577, 3.8496484375, 3.8953660583496093, 4.052254238128662, 4.431234501647949, 4.599901005554199, 4.652210648345947, 4.862302651977539, 5.035719593048095, 5.343199856567383, 5.648118519592285, 5.653760037994385, 5.92943049621582, 6.122050476074219, 6.433161805725097, 6.3507824188232425, 6.731839430236817, 6.62254026260376, 6.815694326019287, 6.914854669189453, 7.088976237487793, 6.962479305267334, 7.0854716506958, 7.233876488494873, 7.325967523193359, 7.349541084289551, 7.525412089538574, 7.408459368133545, 7.531075758361816, 7.6795970176696775, 7.625038201904297, 7.701014516448975, 7.844964042663574, 7.774312676239013, 7.76721838684082], 'val_acc': [0.0477, 0.0892, 0.1385, 0.1691, 0.1955, 0.2118, 0.222, 0.2388, 0.2492, 0.2507, 0.2459, 0.2561, 0.2537, 0.2517, 0.2611, 0.2516, 0.2487, 0.2516, 0.2482, 0.2398, 0.235, 0.2244, 0.2374, 0.2424, 0.2327, 0.2417, 0.2369, 0.2321, 0.2384, 0.2335, 0.2331, 0.2381, 0.2364, 0.2285, 0.2296, 0.2333, 0.2392, 0.2369, 0.231, 0.2339, 0.2351, 0.2358, 0.2396, 0.2355, 0.2342, 0.2377, 0.2353, 0.2409, 0.2346, 0.2344], 'loss': [5.047831169891357, 4.582662380371094, 4.227768583679199, 3.9599411408996583, 3.7371725775909423, 3.552822099761963, 3.3910606929779052, 3.240844896316528, 3.1025374002075194, 2.961397301940918, 2.8244963162231445, 2.690631694564819, 2.5424347161865235, 2.3968860305786133, 2.248894108505249, 2.08382314743042, 1.9288996733474733, 1.7709850692749023, 1.6117412224960328, 1.4406555017089844, 1.2906755989456178, 1.1558734520721436, 1.0144406216812134, 0.8950962263298035, 0.7886745517921447, 0.696241137046814, 0.6245291848564148, 0.5398863710212708, 0.4962474196243286, 0.44226363232135774, 0.4035736873102188, 0.35931753931045535, 0.33108001328706743, 0.3041762026286125, 0.28443762571454045, 0.26027698393106463, 0.24834319202899932, 0.22406056557178497, 0.2108858054935932, 0.2102019789403677, 0.18195527424156666, 0.16359547461867333, 0.1671437414737046, 0.15695890494048595, 0.14138704800665378, 0.14327048982083798, 0.1354668974328041, 0.13398838087648154, 0.11808055531799794, 0.1264525507849455], 'acc': [0.02728, 0.07529, 0.12211, 0.16036, 0.19412, 0.22249, 0.24879, 0.27584, 0.29811, 0.32301, 0.3461, 0.36957, 0.39899, 0.42592, 0.45364, 0.48756, 0.5165, 0.55176, 0.58468, 0.62217, 0.65641, 0.68707, 0.72062, 0.75254, 0.77719, 0.80042, 0.81925, 0.84209, 0.85412, 0.86719, 0.87962, 0.8925, 0.90097, 0.90826, 0.91462, 0.92119, 0.9238, 0.93104, 0.9365, 0.93571, 0.94512, 0.95022, 0.94857, 0.95204, 0.95675, 0.95595, 0.95834, 0.95987, 0.9644, 0.961]}
Training time: 
1385.919432401657
Evaluation results:  [7.811561271667481, 0.2385]
