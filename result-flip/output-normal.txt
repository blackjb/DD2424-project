trainingset size: 100000
validationset size: 10000
input_dims:  (64, 64, 3)
nb_labels:  200
nb_labels: 200
x_train.shape  (100000, 64, 64, 3)
y_train.shape  (100000, 200)
x_test.shape  (10000, 64, 64, 3)
y_test.shape  (10000, 200)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 58, 61, 48)        4080      
_________________________________________________________________
activation_1 (Activation)    (None, 58, 61, 48)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 28, 30, 48)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 30, 128)       30848     
_________________________________________________________________
activation_2 (Activation)    (None, 24, 30, 128)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 14, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 9, 14, 192)        73920     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 7, 14, 192)        110784    
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 5, 14, 128)        73856     
_________________________________________________________________
activation_3 (Activation)    (None, 5, 14, 128)        0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 6, 128)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1536)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              3147776   
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dense_3 (Dense)              (None, 200)               409800    
=================================================================
Total params: 8,047,416
Trainable params: 8,047,416
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
 - 39s - loss: 5.0501 - acc: 0.0265 - val_loss: 4.7404 - val_acc: 0.0582
Epoch 2/50
 - 27s - loss: 4.5889 - acc: 0.0754 - val_loss: 4.3969 - val_acc: 0.1004
Epoch 3/50
 - 27s - loss: 4.2275 - acc: 0.1222 - val_loss: 4.1651 - val_acc: 0.1291
Epoch 4/50
 - 27s - loss: 3.9535 - acc: 0.1611 - val_loss: 4.0826 - val_acc: 0.1467
Epoch 5/50
 - 27s - loss: 3.7296 - acc: 0.1956 - val_loss: 3.7042 - val_acc: 0.1953
Epoch 6/50
 - 27s - loss: 3.5494 - acc: 0.2221 - val_loss: 3.6076 - val_acc: 0.2184
Epoch 7/50
 - 27s - loss: 3.3889 - acc: 0.2477 - val_loss: 3.5420 - val_acc: 0.2275
Epoch 8/50
 - 27s - loss: 3.2337 - acc: 0.2750 - val_loss: 3.4471 - val_acc: 0.2423
Epoch 9/50
 - 27s - loss: 3.0952 - acc: 0.2970 - val_loss: 3.4444 - val_acc: 0.2457
Epoch 10/50
 - 27s - loss: 2.9557 - acc: 0.3214 - val_loss: 3.4516 - val_acc: 0.2483
Epoch 11/50
 - 27s - loss: 2.8160 - acc: 0.3481 - val_loss: 3.4488 - val_acc: 0.2545
Epoch 12/50
 - 27s - loss: 2.6816 - acc: 0.3714 - val_loss: 3.4800 - val_acc: 0.2573
Epoch 13/50
 - 27s - loss: 2.5402 - acc: 0.3959 - val_loss: 3.4523 - val_acc: 0.2619
Epoch 14/50
 - 27s - loss: 2.3918 - acc: 0.4265 - val_loss: 3.4752 - val_acc: 0.2698
Epoch 15/50
 - 27s - loss: 2.2384 - acc: 0.4553 - val_loss: 3.5846 - val_acc: 0.2601
Epoch 16/50
 - 27s - loss: 2.0837 - acc: 0.4867 - val_loss: 3.6686 - val_acc: 0.2602
Epoch 17/50
 - 27s - loss: 1.9253 - acc: 0.5168 - val_loss: 4.0607 - val_acc: 0.2262
Epoch 18/50
 - 27s - loss: 1.7627 - acc: 0.5534 - val_loss: 3.9622 - val_acc: 0.2474
Epoch 19/50
 - 27s - loss: 1.5964 - acc: 0.5874 - val_loss: 4.0751 - val_acc: 0.2469
Epoch 20/50
 - 27s - loss: 1.4530 - acc: 0.6193 - val_loss: 4.3139 - val_acc: 0.2457
Epoch 21/50
 - 27s - loss: 1.2907 - acc: 0.6554 - val_loss: 4.4586 - val_acc: 0.2474
Epoch 22/50
 - 27s - loss: 1.1474 - acc: 0.6897 - val_loss: 4.7018 - val_acc: 0.2330
Epoch 23/50
 - 27s - loss: 1.0098 - acc: 0.7213 - val_loss: 4.8840 - val_acc: 0.2359
Epoch 24/50
 - 27s - loss: 0.8976 - acc: 0.7493 - val_loss: 5.2039 - val_acc: 0.2364
Epoch 25/50
 - 27s - loss: 0.7882 - acc: 0.7766 - val_loss: 5.3601 - val_acc: 0.2389
Epoch 26/50
 - 27s - loss: 0.7081 - acc: 0.7974 - val_loss: 5.5103 - val_acc: 0.2308
Epoch 27/50
 - 27s - loss: 0.6175 - acc: 0.8214 - val_loss: 5.7672 - val_acc: 0.2340
Epoch 28/50
 - 27s - loss: 0.5407 - acc: 0.8420 - val_loss: 5.7770 - val_acc: 0.2366
Epoch 29/50
 - 27s - loss: 0.4899 - acc: 0.8550 - val_loss: 5.9942 - val_acc: 0.2357
Epoch 30/50
 - 27s - loss: 0.4363 - acc: 0.8706 - val_loss: 6.2158 - val_acc: 0.2377
Epoch 31/50
 - 27s - loss: 0.3988 - acc: 0.8807 - val_loss: 6.4860 - val_acc: 0.2329
Epoch 32/50
 - 27s - loss: 0.3590 - acc: 0.8925 - val_loss: 6.5061 - val_acc: 0.2424
Epoch 33/50
 - 27s - loss: 0.3364 - acc: 0.8991 - val_loss: 6.6014 - val_acc: 0.2359
Epoch 34/50
 - 27s - loss: 0.3052 - acc: 0.9071 - val_loss: 6.7580 - val_acc: 0.2333
Epoch 35/50
 - 27s - loss: 0.2784 - acc: 0.9151 - val_loss: 7.0109 - val_acc: 0.2376
Epoch 36/50
 - 27s - loss: 0.2615 - acc: 0.9201 - val_loss: 7.1450 - val_acc: 0.2288
Epoch 37/50
 - 27s - loss: 0.2385 - acc: 0.9277 - val_loss: 7.1859 - val_acc: 0.2320
Epoch 38/50
 - 27s - loss: 0.2302 - acc: 0.9293 - val_loss: 7.1705 - val_acc: 0.2391
Epoch 39/50
 - 27s - loss: 0.2131 - acc: 0.9357 - val_loss: 7.3724 - val_acc: 0.2368
Epoch 40/50
 - 27s - loss: 0.2001 - acc: 0.9389 - val_loss: 7.4214 - val_acc: 0.2378
Epoch 41/50
 - 27s - loss: 0.1801 - acc: 0.9446 - val_loss: 7.2338 - val_acc: 0.2362
Epoch 42/50
 - 27s - loss: 0.1802 - acc: 0.9455 - val_loss: 7.5371 - val_acc: 0.2382
Epoch 43/50
 - 27s - loss: 0.1731 - acc: 0.9473 - val_loss: 7.6111 - val_acc: 0.2386
Epoch 44/50
 - 27s - loss: 0.1525 - acc: 0.9528 - val_loss: 7.6662 - val_acc: 0.2325
Epoch 45/50
 - 27s - loss: 0.1510 - acc: 0.9543 - val_loss: 7.8802 - val_acc: 0.2225
Epoch 46/50
 - 27s - loss: 0.1335 - acc: 0.9596 - val_loss: 7.9264 - val_acc: 0.2323
Epoch 47/50
 - 27s - loss: 0.1332 - acc: 0.9599 - val_loss: 7.8597 - val_acc: 0.2425
Epoch 48/50
 - 27s - loss: 0.1374 - acc: 0.9587 - val_loss: 7.7844 - val_acc: 0.2383
Epoch 49/50
 - 27s - loss: 0.1348 - acc: 0.9590 - val_loss: 7.8047 - val_acc: 0.2387
Epoch 50/50
 - 27s - loss: 0.1306 - acc: 0.9608 - val_loss: 7.7551 - val_acc: 0.2448
training history:
{'val_loss': [4.740400025939941, 4.396919241333007, 4.165111000061035, 4.08260984954834, 3.704169691467285, 3.607610201263428, 3.5419513618469236, 3.4471027618408203, 3.444371426010132, 3.451594458770752, 3.4488000328063966, 3.479969403076172, 3.4522691093444826, 3.475242883682251, 3.5845981006622316, 3.668599178314209, 4.0607100734710695, 3.962176979827881, 4.07512092628479, 4.3138525390625, 4.45858024597168, 4.701754312133789, 4.884036375427246, 5.203917559814453, 5.360120149230957, 5.510273887634277, 5.767157698059082, 5.777031008911133, 5.994246319580078, 6.215833888244629, 6.485983034515381, 6.50612686920166, 6.601394242095947, 6.7579812248229985, 7.0109096496582035, 7.1450164596557615, 7.185870415496826, 7.170469735717774, 7.372382479858398, 7.421392655944824, 7.233788861083984, 7.537053276824951, 7.611106205749512, 7.666237480163574, 7.880156482696533, 7.926350834655762, 7.859703157806396, 7.784351357269287, 7.804695870971679, 7.755078117370606], 'val_acc': [0.0582, 0.1004, 0.1291, 0.1467, 0.1953, 0.2184, 0.2275, 0.2423, 0.2457, 0.2483, 0.2545, 0.2573, 0.2619, 0.2698, 0.2601, 0.2602, 0.2262, 0.2474, 0.2469, 0.2457, 0.2474, 0.233, 0.2359, 0.2364, 0.2389, 0.2308, 0.234, 0.2366, 0.2357, 0.2377, 0.2329, 0.2424, 0.2359, 0.2333, 0.2376, 0.2288, 0.232, 0.2391, 0.2368, 0.2378, 0.2362, 0.2382, 0.2386, 0.2325, 0.2225, 0.2323, 0.2425, 0.2383, 0.2387, 0.2448], 'loss': [5.050045210266113, 4.588935411376953, 4.227424236145019, 3.9534314208984376, 3.729487650299072, 3.5495175940704344, 3.3888281253051757, 3.2337221907806395, 3.0953509577941896, 2.955702669067383, 2.816192339172363, 2.6815877201843263, 2.5403495151519775, 2.3917899711608888, 2.238244485015869, 2.083505240936279, 1.9252129748535156, 1.7628598902893067, 1.5962403472137452, 1.4530221056747437, 1.2908786368560792, 1.1471702038383484, 1.0097335627937316, 0.8976524819183349, 0.7882145692253113, 0.708095801267624, 0.6173381093025208, 0.5406378250312806, 0.48974168715000155, 0.4362672437763214, 0.39881371077537536, 0.35898179251909257, 0.3362960625076294, 0.3052669845986366, 0.2783460806584358, 0.26159978262662886, 0.238486478972435, 0.23031046553254128, 0.21306196925282478, 0.2000467389857769, 0.18018024093270302, 0.18023688972234725, 0.1729915936422348, 0.1524938293749094, 0.15095019933402537, 0.13356505849778652, 0.13325561125427485, 0.13738640181183814, 0.1348405491553247, 0.13059317260950803], 'acc': [0.02653, 0.07542, 0.12227, 0.16109, 0.19561, 0.22209, 0.24765, 0.27503, 0.29703, 0.32139, 0.34806, 0.37135, 0.39583, 0.42654, 0.45532, 0.48674, 0.51682, 0.55331, 0.58739, 0.61927, 0.65539, 0.68979, 0.72133, 0.74928, 0.77659, 0.79736, 0.82141, 0.84201, 0.85507, 0.8706, 0.88069, 0.89253, 0.89911, 0.90713, 0.9151, 0.9201, 0.9277, 0.92925, 0.93571, 0.93893, 0.94455, 0.94546, 0.94732, 0.95282, 0.95433, 0.95955, 0.95993, 0.95871, 0.959, 0.96077]}
Training time: 
1388.7256081104279
Evaluation results:  [7.7686513153076175, 0.2449]
