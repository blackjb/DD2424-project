trainingset size: 100000
validationset size: 10000
input_dims:  (64, 64, 3)
nb_labels:  200
nb_labels: 200
x_train.shape  (100000, 64, 64, 3)
y_train.shape  (100000, 200)
x_test.shape  (10000, 64, 64, 3)
y_test.shape  (10000, 200)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          (None, 12288)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 2048)              25167872  
_________________________________________________________________
dense_2 (Dense)              (None, 2048)              4196352   
_________________________________________________________________
dense_3 (Dense)              (None, 200)               409800    
=================================================================
Total params: 29,774,024
Trainable params: 29,774,024
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 - 47s - loss: 16.0320 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 2/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 3/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 4/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 5/100
 - 39s - loss: 16.0370 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 6/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 7/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 8/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 9/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 10/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 11/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 12/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 13/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 14/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 15/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 16/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 17/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 18/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 19/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 20/100
 - 39s - loss: 16.0370 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 21/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 22/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 23/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 24/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 25/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 26/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 27/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 28/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 29/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 30/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 31/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 32/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 33/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 34/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 35/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 36/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 37/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 38/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 39/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 40/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 41/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 42/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 43/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 44/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 45/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 46/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 47/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 48/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 49/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 50/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 51/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 52/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 53/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 54/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 55/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 56/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 57/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 58/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 59/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 60/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 61/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 62/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 63/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 64/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 65/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 66/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 67/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 68/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 69/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 70/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 71/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 72/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 73/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 74/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 75/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 76/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 77/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 78/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 79/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 80/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 81/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 82/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 83/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 84/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 85/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 86/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 87/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 88/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 89/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 90/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 91/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 92/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 93/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 94/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 95/100
 - 39s - loss: 16.0372 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 96/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 97/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 98/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 99/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
Epoch 100/100
 - 39s - loss: 16.0374 - acc: 0.0050 - val_loss: 16.0375 - val_acc: 0.0050
training history:
{'val_loss': [16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125, 16.0375048828125], 'val_acc': [0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005], 'loss': [16.032310480651855, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370300293, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.03734370300293, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.03734370300293, 16.037343701782227, 16.037343701782227, 16.03734370300293, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.03734370239258, 16.037343701782227, 16.03734370239258, 16.037343701782227, 16.037343701782227, 16.037343701782227], 'acc': [0.00497, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501, 0.00501]}
Training time: 
3931.915187597275
Evaluation results:  [16.0375048828125, 0.005]
